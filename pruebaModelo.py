from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.datasets import load_wine
import numpy as np

# ============================================================================
# 1. CARGA Y EXPLORACI√ìN DE DATOS
# ============================================================================
print("="*70)
print("AN√ÅLISIS DE CLASIFICACI√ìN DE VINOS")
print("="*70)

wine_data = load_wine()

print(f"\nüìä Forma de los datos: {wine_data.data.shape}")
print(f"üìã Caracter√≠sticas: {wine_data.feature_names}")
print(f"üç∑ Clases de vino: {wine_data.target_names}")
print(f"üìà Distribuci√≥n de clases: {np.bincount(wine_data.target)}")
print(f"    Clase 0: {np.bincount(wine_data.target)[0]} muestras")
print(f"    Clase 1: {np.bincount(wine_data.target)[1]} muestras")
print(f"    Clase 2: {np.bincount(wine_data.target)[2]} muestras")

# ============================================================================
# 2. PREPARACI√ìN DE DATOS
# ============================================================================
X = wine_data.data
y = wine_data.target

# Divisi√≥n estratificada para mantener proporciones de clases
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Escalado de caracter√≠sticas
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\n‚úÖ Datos preparados:")
print(f"   Conjunto de entrenamiento: {X_train_scaled.shape}")
print(f"   Conjunto de prueba: {X_test_scaled.shape}")
print(
    f"   Proporci√≥n train/test: {X_train_scaled.shape[0]/wine_data.data.shape[0]*100:.1f}% / {X_test_scaled.shape[0]/wine_data.data.shape[0]*100:.1f}%")

# ============================================================================
# 3. OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS
# ============================================================================
print("\n" + "="*70)
print("OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS")
print("="*70)

# Optimizar Random Forest
print("\nüå≤ Optimizando Random Forest...")
rf_params = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf_grid = GridSearchCV(
    RandomForestClassifier(random_state=42),
    rf_params,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)
rf_grid.fit(X_train_scaled, y_train)

print(f"   Mejores par√°metros encontrados: {rf_grid.best_params_}")
print(
    f"   Mejor puntuaci√≥n en validaci√≥n cruzada: {rf_grid.best_score_:.4f} ({rf_grid.best_score_*100:.2f}%)")

# Optimizar KNN
print("\nüë• Optimizando KNN...")
knn_params = {
    'n_neighbors': range(1, 21),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

knn_grid = GridSearchCV(
    KNeighborsClassifier(),
    knn_params,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)
knn_grid.fit(X_train_scaled, y_train)

print(f"   Mejores par√°metros encontrados: {knn_grid.best_params_}")
print(
    f"   Mejor puntuaci√≥n en validaci√≥n cruzada: {knn_grid.best_score_:.4f} ({knn_grid.best_score_*100:.2f}%)")

# ============================================================================
# 4. ENTRENAMIENTO CON MEJORES MODELOS
# ============================================================================
print("\n" + "="*70)
print("EVALUACI√ìN DE MODELOS")
print("="*70)

# Usar los mejores modelos encontrados
rf_model = rf_grid.best_estimator_
knn_model = knn_grid.best_estimator_

# Predicciones
y_pred_rf = rf_model.predict(X_test_scaled)
y_pred_knn = knn_model.predict(X_test_scaled)

# ============================================================================
# 5. EVALUACI√ìN DETALLADA
# ============================================================================


def evaluar_modelo(nombre, y_true, y_pred, model):
    """Funci√≥n para evaluar y mostrar m√©tricas de un modelo"""
    print(f"\n{'='*70}")
    print(f"üéØ {nombre}")
    print(f"{'='*70}")

    # Exactitud (Accuracy)
    accuracy = accuracy_score(y_true, y_pred)
    print(f"\nüìä Exactitud (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(
        f"   Esto significa que el modelo clasific√≥ correctamente {accuracy*100:.2f}% de las muestras")

    # Validaci√≥n cruzada
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=10)
    print(f"\nüìà Validaci√≥n Cruzada (10 folds):")
    print(
        f"   Puntuaciones por fold: {[f'{score:.4f}' for score in cv_scores]}")
    print(f"   Media: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
    print(
        f"   Esto indica que el modelo es {'muy estable' if cv_scores.std() < 0.05 else 'relativamente estable'} entre diferentes particiones")

    # Matriz de confusi√≥n
    cm = confusion_matrix(y_true, y_pred)
    print(f"\nüî¢ Matriz de Confusi√≥n:")
    print(f"   (Filas = Valor Real, Columnas = Predicci√≥n)")
    print(f"   {cm}")

    # Interpretaci√≥n de la matriz de confusi√≥n
    print(f"\n   Interpretaci√≥n:")
    for i, clase in enumerate(wine_data.target_names):
        correctos = cm[i, i]
        total = cm[i, :].sum()
        print(
            f"   - {clase}: {correctos}/{total} clasificados correctamente ({correctos/total*100:.1f}%)")

    # Reporte de clasificaci√≥n
    print(f"\nüìã Reporte de Clasificaci√≥n Detallado:")
    print(classification_report(y_true, y_pred,
          target_names=wine_data.target_names))

    print(f"\nüí° Explicaci√≥n de m√©tricas:")
    print(f"   - Precision: De todas las predicciones de una clase, cu√°ntas fueron correctas")
    print(f"   - Recall: De todas las muestras reales de una clase, cu√°ntas se detectaron")
    print(f"   - F1-Score: Media arm√≥nica entre precision y recall (balance)")
    print(f"   - Support: N√∫mero de muestras reales de cada clase")

    return accuracy, cm


# Evaluar ambos modelos
acc_rf, cm_rf = evaluar_modelo(
    "Random Forest Classifier", y_test, y_pred_rf, rf_model)
acc_knn, cm_knn = evaluar_modelo(
    "K-Nearest Neighbors Classifier", y_test, y_pred_knn, knn_model)

# ============================================================================
# 6. AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS
# ============================================================================
print("\n" + "="*70)
print("AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS (Random Forest)")
print("="*70)

feature_importance = rf_model.feature_importances_
indices = np.argsort(feature_importance)[::-1]

print("\nüìä Ranking de caracter√≠sticas m√°s importantes:")
for i, idx in enumerate(indices, 1):
    print(
        f"   {i:2d}. {wine_data.feature_names[idx]:30s}: {feature_importance[idx]:.4f} ({feature_importance[idx]*100:.2f}%)")

print("\nüí° Interpretaci√≥n:")
print(f"   Las 3 caracter√≠sticas m√°s importantes son:")
for i in range(3):
    idx = indices[i]
    print(
        f"   - {wine_data.feature_names[idx]}: explica el {feature_importance[idx]*100:.2f}% de la clasificaci√≥n")

# ============================================================================
# 7. CONCLUSIONES Y COMPARACI√ìN
# ============================================================================
print("\n" + "="*70)
print("CONCLUSIONES Y COMPARACI√ìN DE MODELOS")
print("="*70)

print(f"\nüìä Comparaci√≥n de Exactitud:")
print(f"   Random Forest:  {acc_rf:.4f} ({acc_rf*100:.2f}%)")
print(f"   KNN:            {acc_knn:.4f} ({acc_knn*100:.2f}%)")
print(
    f"   Diferencia:     {abs(acc_rf - acc_knn):.4f} ({abs(acc_rf - acc_knn)*100:.2f} puntos porcentuales)")

mejor_modelo = "Random Forest" if acc_rf > acc_knn else "KNN"
mejor_accuracy = max(acc_rf, acc_knn)

print(
    f"\nüèÜ Mejor modelo: {mejor_modelo} con {mejor_accuracy:.4f} ({mejor_accuracy*100:.2f}%) de exactitud")




